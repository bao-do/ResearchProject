\documentclass[a4paper,10pt]{article}

\usepackage{geometry}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{bbm}
\usepackage{xcolor}
\usepackage{hyperref}

\theoremstyle{definition} % Style pour les définitions
\newtheorem{definition}{Définition}[section]

\theoremstyle{definition} % Style pour les propositions et lemmes
\newtheorem{proposition}[definition]{Proposition}
\newtheorem{lemma}[definition]{Lemme}

\theoremstyle{definition} % Style pour les remarques
\newtheorem{theorem}[definition]{Théorème}

\theoremstyle{definition} % Style pour les remarques
\newtheorem{remark}[definition]{Remarque}

\newcommand{\E}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Xc}{\mathcal{X}}
\newcommand{\Ac}{\mathcal{A}}
\newcommand{\dist}{\mathrm{dist}}
\newcommand{\eqdef}{\stackrel{\mathrm{def}}{=}}
\newcommand{\argmin}{\mathop{\mathrm{argmin}}}
\newcommand{\argmax}{\mathop{\mathrm{argmax}}}
\newcommand{\xmap}{x_{\scalebox{0.5}{\textrm{MAP}}}}
\newcommand{\xmmse}{x_{\scalebox{0.5}{\textrm{MMSE}}}}
\newcommand{\xmarginal}{x_{\scalebox{0.5}{\textrm{MARG}}}}
\newcommand{\todo}[1]{\textcolor{red}{\textbf{TODO:} #1}}


\title{Projet de Recherche}
\author{Quoc-Bao DO}
\date{Fevrier 2024}


\begin{document}

\maketitle

\section{Modèle de diffusion}

    En modélisation probabiliste, il est fréquent de devoir générer des échantillons à partir d'une distribution de données dont la forme précise est inconnue ou trop complexe pour permettre un échantillonnage direct. Les modèles de diffusion offrent une solution à ce problème en apprenant une équation différentielle inhomogène dans le temps, qui transforme progressivement des échantillons issus d'une distribution gaussienne simple en échantillons correspondant à la distribution cible, plus complexe.

Considérons une équation différentielle stochastique dépendante du temps (Itô), donnée comme suit :
    \begin{equation}\label{eq:SDE}
         d\phi_t = f_t(\phi_t)dt + g_tdW_t
    \end{equation}
    avec 
    \begin{itemize}
        \item $\phi \in \R^N$
        \item $f_t:\R^N \rightarrow \R^N$ de classe $C^1$, et $f_t$ linéairement croissante, i.e $\exists C > 0$ tel que $\|f_t(\phi)\| \leq C(1+|\ \phi \|)$
        \item $g_t : \R \rightarrow \R$ de classe $C^2$
        \item $W_t$ est un processus de Wiener standard de dimension N, c'est-à-dire tel que 
            \begin{equation*}
                \langle W_t^i, W_t^j \rangle =
                    \begin{cases}    
                        t & \textrm{ si } i=j \\
                        0 & \textrm{sinon},
                    \end{cases}
            \end{equation*}
            où $W^i$ et $W^j$ sont les $i$-ème et $j$-ème coordonnées de $W_t$ respectivement. 
        % \item $\frac{\partial \pi_t}{\partial t}$ existe $\forall t \geq 0$
        % \item $\pi_0$ décroit rapidement à l'infini, i.e $lim_{\|\phi\| \rightarrow \infty} \| \phi \|^k |\pi_0(\phi)| = 0$
    \end{itemize}
    \begin{remark}
        La condition que $f_t$ soit linéairement croissante rassure l'existence de solution de la SDE.
    \end{remark}

\begin{proposition}[Fokker – Planck equation] 
Sous les hypothèses précédentes, le flux sur les distributions de probabilité $\pi_t$ de $\phi_t$ pour $t \geq 0$ est donné par :
    \begin{equation}\label{eq:Fokker-Planck}
        \frac{\partial\pi_t}{\partial t} = -\nabla \cdot (f_t \pi_t) + \frac{1}{2}\nabla^2(g_t^2\pi_t)
    \end{equation}
\end{proposition}
\begin{proof}
Commençons par un rappel sur la formule d'Itô . 
\begin{theorem}[Formule d'Itô \cite{Oksendal2003}]
Soit \( X(t) \) un processus d’Itô de dimension \( n \) vérifiant  
\[
dX(t) = u(t, X(t)) dt + v(t, X(t)) dB(t),
\]
où :
\begin{itemize}
    \item \( X(t) \in \mathbb{R}^n \) est le processus d’état,
    \item \( u(t, X(t)) \in \mathbb{R}^n \) est le terme de dérive,
    \item \( v(t, X(t)) \in \mathbb{R}^{n \times m} \) est la matrice de diffusion,
    \item \( B(t) \in \mathbb{R}^m \) est un mouvement brownien standard de dimension \( m \).
\end{itemize}

Soit \( g: [0, \infty) \times \mathbb{R}^n \to \mathbb{R}^p \) une fonction deux fois continûment différentiable.  
On définit le processus transformé :
\[
Y(t) = g(t, X(t)),
\]
où \( Y(t) \in \mathbb{R}^p \).  
Alors, \( Y(t) \) satisfait l’équation d’Itô :
\[
dY_k = \frac{\partial g_k}{\partial t} dt 
+ \sum_{i=1}^{n} \frac{\partial g_k}{\partial x_i} u_i dt 
+ \sum_{i=1}^{n} \sum_{j=1}^{m} \frac{\partial g_k}{\partial x_i} v_{ij} dB_j
+ \frac{1}{2} \sum_{i,j=1}^{n} \sum_{r=1}^{m} v_{ir} v_{jr} \frac{\partial^2 g_k}{\partial x_i \partial x_j} dt.
\]
\end{theorem}
\vspace{3em}



Soit une fonction test $F: \mathbb{R}^N \rightarrow \mathbb{R}$, de classe $C^{\infty}$, à support compact. En utilisant la formule d'Ito, on obtient
%     \[dF(\phi_t) = \sum_{i=1}^N \frac{\partial F(\phi_t)}{\partial x_i} d\phi_t^i + \frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \frac{\partial^2 F(\phi_t)}{\partial x_i^2}d\langle \phi^i,\phi^j\rangle_t\]
% En utilisant l'équation \eqref{eq:SDE} et en notant que 
%  on obtient:
\begin{align*}
    dF(\phi_t) &= \sum_{i=1}^N \frac{\partial F(\phi_t)}{\partial x_i} (f^i_t(\phi_t)dt + g_tdW^i_t) + \frac{1}{2} \sum_{i=1}^N  \frac{\partial^2 F(\phi_t)}{\partial x_i^2} g_t^2 dt \\
    &= \left(\sum_{i=1}^N \frac{\partial F(\phi_t)}{\partial x_i} f^i_t(\phi_t) + \frac{1}{2} \sum_{i=1}^N  \frac{\partial^2 F(\phi_t)}{\partial x_i^2} g_t^2\right)dt + \sum_{i=1}^N \frac{\partial F(\phi_t)}{\partial x_i}  g_t^2dW^i_t
\end{align*}

Le terme $dW_t^i$ disparaît en prenant l'espérance  (car $\mathbb{E}[dW_t^i] = 0$ ), donc :

\[\E{dF(\phi_t)} = \E{\left(\sum_{i=1}^N \frac{\partial F(\phi_t)}{\partial x_i} f^i_t(\phi_t) + \frac{1}{2} \sum_{i=1}^N \frac{\partial^2 F(\phi_t)}{\partial x_i^2} g_t^2\right)dt}\]

Ou encore, en utilisant la linéarité de l'opérateur espérance, on peut sortir la dérivée, l'équation ci-dessus s'écrit :

\[ d\E{F(\phi_t)} = \E{\sum_{i=1}^N \frac{\partial F(\phi_t)}{\partial x_i} f^i_t(\phi_t) + \frac{1}{2} \sum_{i=1}^N \frac{\partial^2 F(\phi_t)}{\partial x_i^2} g_t^2}dt\]

Ainsi,
\begin{align}
    \frac{d\E{F(\phi_t)}}{dt} &= \E{\sum_{i=1}^N \frac{\partial F(\phi_t)}{\partial x_i} f^i_t(\phi_t) + \frac{1}{2} \sum_{i=1}^N  \frac{\partial^2 F(\phi_t)}{\partial x_i^2}g_t^2} \nonumber \\
    &=\E{\sum_{i=1}^N \frac{\partial F(\phi_t)}{\partial x_i} f^i_t(\phi_t)} + \E{\frac{1}{2} \sum_{i=1}^N  \frac{\partial^2 F(\phi_t)}{\partial x_i^2} g_t^2} \nonumber\\
    &=\E{ \nabla\ F(\phi_t) \cdot f_t(\phi_t)} + \frac{1}{2}\E{\nabla^2 F(\phi_t) g_t^2} \label{eq:EsperanceEgality}
\end{align}

$F$ est continue, donc mesurable, supposons que $\phi \rightarrow \frac{\partial\pi_t(\phi)}{\partial t}$ existe, $\phi \rightarrow F(\phi)\frac{\partial\pi_t(\phi)}{\partial t}$ est intégrable en $\R^N$ car F est à support compact. D'après la règle de Leibniz, le premier terme à droite s'écrit :

\[\frac{d\mathbb{E}[F(\phi_t)]}{dt} = \frac{d (\int_{\mathbb{R^N}} F(\phi) \pi_t(\phi) d\phi)} {dt} = \int_{\mathbb{R^N}}F(\phi)\frac{\partial\pi_t(\phi)}{\partial t} d\phi\]
\vspace{2em}

Nous allons rappeler la première identité de Green (Green's first identity) qui est fort utile dans la suite.


\begin{theorem}[Première identité de Green]
Soit $\Omega \subset \R^n$, on se donne une fonction $u : \Omega \rightarrow \R$, $u \in C^2$ et une autre fonction $v : \Omega \rightarrow \R$, $v \in C^1$, alors :
\begin{equation}\label{eq:GreenId}
\int_\Omega (v(x)\nabla^2 u(x) + \nabla u(x) \cdot \nabla v(x)) dx = \int_{\partial\Omega} v \nabla u \cdot n dS
\end{equation}
Avec n le vecteur normal unitaire à la frontière $\partial\Omega$ et $dS$ la mesure de frontière sur $\partial\Omega$.
\end{theorem}
\vspace{3em}

Supposons qu'il existe une fonction $v_t$ telle que $\nabla_{\phi} v_t = f_t \pi_t$.

On utilise la première identité de Green sur le premier terme à gauche en remarquant que l'intégrale sur le bord s'annule car F est à support compact, on obtient :
\begin{align*}
    \E{\nabla\ F(\phi_t)\cdot f_t(\phi_t)}  &=\int_{\mathbb{R^N}} \nabla\ F(\phi)\cdot \big(f_t(\phi) \pi_t(\phi) \bigr)d\phi \\
    &= - \int_{\mathbb{R}^N}F(\phi) (\nabla \cdot f_t(\phi)\pi_t(\phi))d\phi
\end{align*}

De la même manière, en appliquant l'intégration par parties deux fois sur le deuxième terme à droite, on obtient :
\begin{align*}
    \E{\nabla^2 F(\phi_t) g_t^2} &= \int_{\mathbb{R}^N } \nabla^2 F(\phi) g_t^2 \pi_t(\phi)d\phi\\
    &= -\int_{\R^N}\nabla F(\phi) \cdot\nabla(g_t^2\pi_t(\phi)) d\phi\\
    &= \int_{\mathbb{R}^N } F(\phi) \nabla^2(g_t^2 \pi_t(\phi)) d\phi
\end{align*}

Injectons les résultats précédents dans l'équation \eqref{eq:EsperanceEgality} :
\[\int_{\mathbb{R^N}}F(\phi)\frac{\partial\pi_t(\phi)}{\partial t} d\phi = - \int_{\mathbb{R}^N}F(\phi) (\nabla \cdot f_t(\phi)\pi_t(\phi))d\phi + \frac{1}{2}\int_{\mathbb{R}^N } F(\phi) \nabla^2(g_t^2 \pi_t(\phi)) d\phi\]

Cette relation est vraie pour toute fonction de test $F \in C_c^{\infty}$ (i.e ensemble des fonctions infiniment dérivables à support compact), la théorie de distribution nous dit : 
\[\frac{\partial\pi_t(\phi)}{\partial t} = -\nabla \cdot (f_t(\phi)\pi_t(\phi)) + \frac{1}{2}\nabla^2(g_t^2 \pi_t(\phi)) \quad \] 
\end{proof}


Le processus avant est généralement construit de sorte que lorsque $t \rightarrow \infty$ (ou $t \rightarrow T$ pour un certain temps fini $T$), la distribution $\pi_t$ converge vers une distribution connue et bien définie $\pi_{\infty}$, souvent choisie comme une gaussienne à variance finie.

Dans le contexte des modèles de diffusion, et plus précisément des modèles implicites de diffusion pour le débruitage (DDIMs), on cherche un champ de vecteurs déterministe et dépendant du temps $v_t(\phi)$ qui reproduit la même transformation des distributions de probabilité que l'équation stochastique précédente. Cette reformulation permet d'inverser le processus de diffusion de manière déterministe :
\begin{itemize}
    \item On commence par échantillonner $\phi_T \sim \pi_t$
    \item Puis on fait évoluer l'échantillon en arrière dans temps, de $t=T$ à $t = 0$, en résolvant l'EDO suivante :
    \begin{equation}
        \frac{d\phi_t}{dt} = v_t(\phi_t)
    \end{equation}
\end{itemize}

D'après l'équation de Fokker-Planck, l'évolution de la distribution $\phi_t$ est donnée par l'équation de transport suivante :
\[\frac{d\pi_t(\phi)}{dt} =-\nabla \cdot [v_t(\phi)\pi_t(\phi)]\]

Notre but est d'identifier la fonction $v_t$ déterministe et dépendante en temps de sorte que l'équation au dessus produise la même évolution que l'équation (2) (flow-matching en anglais). Pour ce faire, on récrit (2) comme suit :
\[\frac{d\pi_t(\phi)}{dt} =\nabla \cdot([f_t(\phi)-\frac{1}{2}g_t^2\nabla log\pi_t(\phi)]\pi_t(\phi))\]

Ainsi,
\[v_t(\phi) =f_t(\phi)-\frac{1}{2}g_t^2\nabla log\pi_t(\phi) \]
On note $s_t(\phi) = \nabla log\pi_t(\phi)$ et on appelle $s_t$ la fonction de score (score function en anglais). Déterminer cette fonction joue un rôle hyper important pour pouvoir retrouver l'image initial $\phi_0$.\\

Le choix le plus courant de processus direct est un processus Ornstein-Uhlenbeck inhomogène de la forme suivante :
\begin{equation}\label{eq:OU}
    d\phi_t = -\gamma_t\phi_tdt + \sqrt{2\gamma_t}dW_t
\end{equation}
Ainsi, le fluide de probabilité est donné par :
\begin{equation}\label{eq:backward}
    v_t(\phi) = -\gamma_t(\phi+\nabla log \pi_t(\phi)) = -\gamma_t(\phi+s_t(\phi))
\end{equation}

Le choix de processus de forward comme l'équation \eqref{eq:OU} car pour tout $t \geq 0$, la solution $\phi_t$ est un vecteur gaussien que l'on peut facilement échantillonner. 


\begin{proposition}
    La solution $\phi_t$ de l'équation \eqref{eq:OU} est donnée par :
    \begin{equation}\label{eq:solforphi}
        \phi_t = \sqrt{\bar{\alpha_t}}\phi_0 + \sqrt{1-\bar{\alpha_t}}\eta_t
    \end{equation}
    Avec $\phi_0 \sim \pi_0$ qui est la distribution des images initiales qu'on veut échantillonner, $\eta_t$ est un vecteur gaussien isotropique, i.e $\eta_t \sim \mathcal{N}(0, I_N)$, et $\bar{\alpha_t}$ est défini par: \[\bar{\alpha_t} = \exp{\left(-2\int_0^t \gamma_s ds\right)}\]
\end{proposition}
\begin{proof}
    D'après l'équation \eqref{eq:OU}:
    \[d\phi_t^i = -\gamma_t \phi_t^i dt + \sqrt{2\gamma_t}dW_t^i, \quad \forall i=1,2,\dots,N\] 
    
    Posons $\mu_t = exp{\left(\int_0^t \gamma_s ds\right)}, \quad \forall t \geq 0$.
    
    Soit $Y_t$ un processus stochastique défini par $Y_t \coloneqq f(t,\phi_t^i)= \mu_t \phi_t^i$.
    
    En utilisant la formule d'Ito, on obtient:
    \[dY_t = \frac{\partial f(t,\phi_t^i)}{\partial t} dt + \frac{\partial f(t,\phi_t^i)}{\partial x} d\phi_t + \frac{1}{2}\frac{\partial^2f(t,\phi_t^i)}{\partial x^2}d\langle\phi,\phi\rangle_t\]

    En particulier:
    \begin{itemize}
        \item $\frac{\partial f(t,\phi_t^i)}{\partial t} = \gamma_t \mu_t \phi_t^i$
        \item $\frac{\partial f(t,\phi_t^i)}{\partial x} = \mu_t$
        \item $\frac{\partial^2f(t,\phi_t^i)}{\partial x^2}=0$
    \end{itemize}

    Ainsi,
    \begin{align*}
        dY_t &= \gamma_t \mu_t \phi_t^i dt + \mu_t d\phi_t^i\\
        &= \gamma_t \mu_t \phi_t^i dt + \mu_t (-\gamma_t \phi_t^i dt + \sqrt{2\gamma_t}dW_t^i)\\
        &= \mu_t\sqrt{2\gamma_t}dW_t^i
    \end{align*}
    
    On passe à l'intégrale pour 2 côtés :
    \[Y_t = Y_0 + \int_0^t \mu_s\sqrt{2\gamma_s}dW_s^i\]

    Remplaçons $Y_t$ par $\mu_t \phi_t^i$, puis divisons les 2 côtés par $\mu_t$ pour faire apparaitre $\phi_t^i$, on obtient:
    \begin{align*}
        \phi_t^i &= \frac{1}{\mu_t}\phi_0^i + \frac{1}{\mu_t} \int_0^t \mu_s\sqrt{2\gamma_s}dW_s^i \\
        &= \sqrt{\bar{\alpha_t}}\phi_0^i + \frac{1}{\mu_t} \int_0^t \mu_s\sqrt{2\gamma_s}dW_s^i
    \end{align*}

    Notons $Z_t = \int_0^t\mu_s\sqrt{2\gamma_s}dW_s^i$. On remarque que $Z_t$ est une intégrale d'Itô par rapport à un mouvement brownien. On peut réécrire cette intégrale sous forme :
    \[Z_t=\int_0^t\mu_s\sqrt{2\gamma_s}dW_s^i = \lim_{h\rightarrow 0} \sum_{j=1}^{n} \mu_{t_j}\sqrt{2\gamma_{t_j}}(W^i_{t_j}-W^i_{t_{j-1}})\]
    Avec $t_0=0 < t_1<\dots<t_{n-1} < t_{n} = t$ une sous-division de l'intervalle $[0,t]$ et $h \coloneqq max_{j = 1,2,\dots,n} |t_j - t_{j-1}|$

    Comme les incréments d'un mouvement brownien sont les variables gaussiennes centrées et indépendantes l'une de l'autre, $Z_t$ est une variable gaussienne centrée dont la variance vaut $\int_0^t(\mu_s\sqrt{2\gamma_s})^2 ds $. On va calculer cette variance :
    \begin{align*}
        \int_0^t(\mu_s\sqrt{2\gamma_s})^2ds &= \int_0^t \exp\left(2 \int_0^s \gamma_xdx\right) 2 \gamma_s ds \\ 
        &=\int_0^t \exp\left(2 \int_0^s \gamma_xdx\right) d\left(2 \int_0^s \gamma_xdx\right)\\
        &= \exp\left(2 \int_0^t \gamma_xdx\right) -1
    \end{align*}
    
    Alors, $Z_t$ représente une variable gaussienne telle que  $Z_t \sim \mathcal{N}\left(0, \exp\left(2 \int_0^t \gamma_xdx\right) -1\right) $.
    
    Par conséquent, 
    \[\frac{1}{\mu_t}Z_t \sim \mathcal{N}\left(0, 1-\exp\left(-2 \int_0^t \gamma_xdx\right)\right)\]
    
    D'où :
    \[\frac{1}{\mu_t}Z_t \sim \mathcal{N}\left(0, 1-\bar{\alpha_t}\right)\]

    On injecte ce résultat dans l'équation de $\phi_t^i$, on obtient :
    \[\phi_t^i = \sqrt{\bar{\alpha_t}}\phi_0^i + \theta_t\]
    avec $\theta_t \sim \sqrt{1-\bar{\alpha_t}}\mathcal{N}\left(0, 1\right)$

    On a bien obtenu l'expression pour chaque composante de $\phi_t$. On remarque que la $i$-ème composante $\phi_t^i$ dépend de $\phi_0^i$ et la $i$-ème composante de $W_t$. Comme $W_t$ est un mouvement brownien standard, ses composantes sont indépendantes l'une de l'autre. Ainsi, sous l'hypothèse que les composantes de $\phi_0$ sont indépendantes l'une de l'autre, les composantes de $\phi_t$ sont indépendantes l'une de l'autre. Un vecteur dont les composantes sont les gaussiennes indépendantes est un vecteur gaussien avec la matrice de covariance diagonale. En particulier, comme les composantes de $\phi_t$ ont la même variance, $\phi_t$ s'écrit comme suit :
    \[\phi_t = \sqrt{\bar{\alpha_t}}\phi_0 + \sqrt{1-\bar{\alpha_t}}\eta_t \quad \text{avec} \quad \eta_t \sim \mathcal{N}(0, I_N)\] 
\end{proof}




\bibliographystyle{plain}
\bibliography{bibliography} 
\end{document}